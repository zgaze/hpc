# 多线程

## 进程和线程
C/C++源文件经过编译器处理后，会产生可执行程序文件，可执行程序文件是一个静态的概念。可执行程序在操作系统上的一次执行则对应一个进程，进程是一个动态的概念，同一份可执行文件执行多次，则会产生多个进程实体。

线程是最小执行单元、是操作系统中被调度执行的最小单位，即操作系统调度线程执行，而非进程。

一个进程内可以有多个线程，每个进程有独立的地址空间，同一进程内的多个线程共享地址空间。

## 堆栈
每个线程都会有一个入口函数，线程从入口函数开始执行，一行代码接着一行代码执行，中间它可能会调用其他函数，那么它的控制流就转到了被调用的函数继续执行，被调用函数里还可以继续调用其他函数，这样便形成一个函数调用链。

被调用函数执行完便返回调用该函数的地方，继续执行后面的语句，等到函数执行完再返回到它的调用函数，一步步返回到线程的入口函数，等到入口函数执行完成，线程的执行流程便结束了。

假设某线程的入口函数是a，a函数里调用了b，b函数里调用了c，那么调用链是：a() -> b() -> c()；c函数执行完返回b，b函数执行完返回a，所以返回链是调用链的逆序：c() -> b() -> a()。

线程在执行过程中，每个被调用的函数会对应到一帧（Frame），每帧会有一个帧编号，当前正被执行的函数对应的帧号为0，调用它的函数对应的帧号为1，多个帧形成调用堆栈，栈帧反映函数调用关系，每个线程有独立的调用堆栈，两个特殊的寄存器用于界定当前帧的顶和底，之前的栈帧信息被保存在栈内存里，函数内的局部变量也保存在该线程私有的栈内存里。

当b函数被调用执行时，栈的深度是2，c函数被执行时，帧的深度是3，当c函数被执行完，返回到b函数里调用c的地方，栈的深度又变成了2，当b函数执行完，返回a，栈的深度就变成了1，可见调用堆栈是动态伸缩的，每个线程的栈内存很小，只有几兆，过深的递归、函数内定义过大局部变量（通常是大的数组）会有爆栈的风险。

## 执行流
一个线程里被执行的代码行会被编译成汇编指令，所以，依次执行的代码，会转变为一个被依次执行的指令序列，这个指令序列就是执行流，一个执行流对应一个线程，多个执行流并发执行的情况就叫多线程程序。

注意：这个指令序列跟代码顺序不一样，代码中的条件分支和跳转返回语句等会影响执行流。

## 逻辑线程和硬件线程
线程的执行逻辑由代码描述，比如编写一个函数实现对一个整型数组的元素求和：
```c++
int Sum(int a[], int n) {
    int x = 0;
    for (int i = 0; i < n; ++i) 
        x += a[i];
    return x;
}
```
这个函数逻辑很简单，它没有再调用其他函数，我们可以开一个线程去执行这个函数对某数组求和。

函数描述了逻辑，即要做什么、以及怎么做，它偏设计，它没有描述物质，即没有描述这个事情由谁做，事情最终需要派发到实体去完成。

程序上的线程是一个逻辑上的概念，也叫任务、软线程、逻辑线程；需要跟芯片的线程概念做区分，芯片上的线程的概念，通常指为执行指令序列而配套的硬件单元，所以也叫硬线程。

一个软件线程由哪个CPU核心去执行、以及何时执行，则不归应用程序员管，它由操作系统决定，操作系统中的调度系统负责这项工作。

## 函数、线程和核的关系
数组求和例子，如果数组特别大，则求和耗时长，那么，可以把这个整型数组分成多个小数组，或者表示成二维数组（数组的数组），每个线程负责一个小数组的求和，多个线程并发执行，最后再累加结果。所以，为了提升处理速度，可以让多个线程执行相同或者相似的计算逻辑。同样的处理逻辑可以有多个执行实例，即多个线程。

当然，也可以为两个线程指定不同的入口函数，让各线程执行不同的计算逻辑。

打个比方，假设有遛狗、扫地、做饭3项工作要做。

- 遛狗就是为狗系上绳子然后牵着它在小区里溜达一圈，这句话就描述了遛狗的逻辑，即对应到函数定义，它是一个对应到设计的、静态的概念。
- 每项工作，最终需要人去做，人就对应到硬件：CPU/Core，是工作被完成的物质基础。

那什么是线程？某人做某项工作，比如张三在遛狗，那就对应一个线程，李四在扫地，则表示另一个线程在执行，可见线程是一个对应到执行的动态的概念。

但动态概念的线程，并不意味着某个线程会一直处于执行中，比如李四扫地过程中接到一个电话，李四需要去处理更紧急的事情（接电话），则扫地这个事情被挂起，李四打完电话后继续扫地，则这个线程会被继续执行。

那上面描述的情况，3项工作会对应几个线程呢？是不是3项工作就对应3个线程呢？答案：并不是。

比如有2个房间，让2个人去打扫，1个人打扫一个房间，那么就是2个线程；也可以1个人负责，一个房间接着一个房间的打扫，那么就是1个线程。

所以多线程并不一定需要多CPU多Core，即单CPU单Core系统依然可以运行多线程程序，虽然最大化利用多CPU多Core的处理能力是多线程程序设计的一个重要目标。

可以1个人把3项工作都做了，先遛狗、再扫地，然后做饭，显然1个人无法同时做多件事情，单CPU单Core也不行，操作系统通过时间分片技术应对远多于CPU数的多任务的挑战。

## 时间分片
CPU先执行一段时间线程A，然后再执行一段时间线程B，然后再执行一段时间线程A，这就是CPU时间分片，时间分片是对调度策略的一个极度简化，实际上操作系统的调度策略非常精细，要比简单的时间分片复杂的多。如果一秒钟被分成大量的非常短的时间片，比如1000个1毫秒的时间片，一毫秒对人的感官而言太短了，以致于用户觉察不到延迟，仿佛计算机被该用户的任务所独占（实际上并不是），这要归功于计算机系统的进程的抽象。

## 上下文切换
把当前正在CPU上运行的任务迁走，并挑选一个新任务到CPU上执行的过程叫调度，任务调度的过程会发生上下文切换（context swap），即保存当前CPU上正在运行的线程状态，并恢复将要被执行的线程的状态，这个任务由操作系统完成，需要占用CPU时间（sys time）。

## 并发和并行
- 并发：多个任务被交错执行的情况被称为多任务（线程）并发；如果一个任务的开始时间，不晚于另一个任务的结束时间，那么这2个任务就是并发执行的。
- 并行：如果多个任务在多个CPU或者多核上同时执行，齐头并进，则称为多任务并行，并行可以发生在单机多线程，也可以发生在分布式多机环境。

并发并不一定是并行，但并行一定是并发。比如在单CPU单Core的机器上，执行2个线程，只要这2个线程的开始+结束时间有重叠，那么这2个线程就是并发执行的，但这2个线程不是并行执行的，因为处理器在执行线程1的时候无法同时执行线程2。

## 多线程同步
因为进程内的多个线程共享同一地址空间，所以一个进程内的所有线程共享内存，例如：进程内的所有线程都可以读写某全局变量。

多个线程对同一数据的并发访问叫数据竞争，数据竞争不加控制，会出现数据不一致的情况，这种情况需要避免，协调多线程对共享数据的并发访问叫多线程同步，操作系统和编程语言提供多种多线程同步的机制。

每个C/C++进程的地址空间，分成：文本区、初始化数据区、未初始化数据区（bss）、堆、共享内存、栈。

初始化数据区和未初始化数据区合称全局数据区，一个进程一个全局数据区。
栈内存被进程内的所有线程切分，一个进程一块栈内存，每个线程有自己的一片栈内存，所以，栈内存是线程私有的，线程的栈内存对其他线程不可见。

先看看C/C++程序的内存布局：
- 全局变量和静态全局变量位于全局数据区，它是多线程可见的，即每个线程都可以读写某全局变量。
- 局部变量位于栈中，每个线程有它自己独立的栈，位于线程私有栈内的局部变量对其他线程不可见，所以函数内的局部变量不需要同步。不借助特殊手段拿不到另一个线程中运行的函数的局部变量地址，所以也访问不了。
- 函数参数位于寄存器或栈中，其他线程不可见，同样不需要同步。
- 静态局部变量位于全局数据区，它是多线程可见的，多个线程执行同一个函数会使用同一个静态局部变量。

再看看多线程编程，哪些情况需要同步，哪些情况不需要同步：
- 如果不存在数据共享，则不需要同步。
- 如果存在共享的数据，又分2种情况：
    - 如果多线程对共享数据只读，那么不需要同步。
    - 如果多线程对共享数据读写，那么通常需要同步。

注意：
- 不存在数据共享并非指不存在可以被多线程访问的数据，而是指每个线程不读写被其他线程读写的数据，即并非不能，而是不做。同一进程内的所有线程共享地址空间，所以，理论上，一个线程可以访问其他线程的任何数据，比如把某个线程的局部变量地址通过全局变量或者消息传递给其他线程。
- 多线程读写同一数据，通常需要同步，而非必须，如果能够容忍这种数据竞争导致的问题，则同步也不是必须的。

### 两个线程读写同一个数据
例子1：假设有1个长度为256的字符数组表示的消息`msg`，`write_msg()`函数实现对`msg`的写操作，如下：
```c++
char msg[256] = "this is old msg";

char* read_msg() {
    return msg;
}

void write_msg(char new_msg[], size_t len) {
    memcpy(msg, new_msg, std::min(len, sizeof(msg)));
}

void thread1() {
    char new_msg[256] = "this is new msg, it's too looooooong";
    write_msg(new_msg, sizeof(new_msg));
}

void thread2() {
    printf("msg=%s\n", read_msg());
}
```
如果线程1调用write_msg()，因为msg的长度是256字节，完成256字节的内存写入需要多个指令周期，在线程1写入新消息期间，如果线程2调用read_msg，则线程2可能读到不一致的数据（即可能读到"this is new msg"，而后半段"it's very..."还没来得及写入），它不是完整的新消息，不是我们想要的。

例子2：比如”用数组实现队列“，该队列通常会有一个元素的数组和2个游标，游标用于记录队首head和队尾tail的位置。
```c++
template <typename T>
class Queue {
    static const int Q_CAPACITY = 100;
public:
    // 入队
    bool push(const T& element) {
        if (element_num == Q_CAPACITY) return false;
        tail = (++tail) % Q_CAPACITY;
        elements[tail] = element;
        ++element_num;
        return true;
    }

    // 出队
    void pop() {
        assert(!empty());
        head = (++head) % Q_CAPACITY;
        --element_num;
    }

    bool empty() const { 
        return element_num == 0; 
    }

    const T& front() const {
        assert(!empty());
        return elements[head];
    }
private:
    T elements[Q_CAPACITY];
    int element_num = 0;
    int head = 0;
    int tail = -1;
};
```
队列的`push`接口，先移动tail游标，再把元素添加到队尾，但**移动游标+添加元素**这2个操作，不能在一个指令周期内完成，所以，读线程可能会在写线程**移动tail游标后**穿插进来，而此时元素还没有添加好，同样会有问题。

例子3：比如对于二叉搜索树的节点，一个结构体有多个成分：
- 一个指向父节点的指针
- 一个指向左子树的指针
- 一个指向右子树的指针
```c++
struct Node {
    struct Node *parent;
    struct Node *left_child, *right_child;
};
```
这3个成分是有关联的，将节点加入BST，要设置这3个指针域，从BST删除该节点，要修改该节点的父、左孩子节点、右孩子节点的指针域。对多个指针域的修改，不能在一个指令周期完成，如果完成了一个成分的写入，还没来得其他成分写入的时候，被其他线程读到了，则会出错。

### 两个线程写同一个数据
考虑两个线程对同一个整型变量同时做自增，变量的初始值是0。
```c++
int x = 0; // 初始值为0
void thread1() { ++x; }
void thread2() { ++x; }
```

简单的自增`++x;`操作，包括三步：
- 加载: 从内存中读取变量x的值存放到寄存器。
- 更新: 在寄存器里完成自增。
- 保存: 把位于寄存器中的新值写入内存。

如果两个线程并发执行`++x;`，我们预期2个线程完成自增后，变量`x`的值为2，让我们看看真实情况是什么样的？

1. 如果2个线程，先后执行自增，在时间上完成错开，那么`x`的最终值是2，符合预期。但多线程并发并不能确保对一个变量的访问在时间上完全错开。
2. 如果2个线程，在执行自增（`++x;`）的时候，时间没有完全错开：
    - 首先，线程1把x读到寄存器，线程2也把x的值加载到寄存器，此时，寄存器里的值都是0。
    - 然后，线程1完成自增，更新寄存器里的值（0变1），此时线程2也完成自增，更新寄存器里的值（0变1）。
    - 然后，线程1将更新后的新值1写入变量`x`的内存位置。
    - 最后，线程2将更新后的新值1写入内存（同一内存位置），变量`x`的最终值是1，不符合预期。

之所以会出现不符合预期的情况，主要是因为“加载+更新+保存”这3个步骤不能在一个内存周期内完成，多个线程对同一变量并发读写，不加同步的话会出现数据不一致。

#### 原子性
如果**load、update、store**这3个步骤是不可分割的整体，即自增操作`++x`满足原子性，上面的程序便不会有问题，因为这样的话，2个线程并发执行`++x`，只会有2个结果：
- 线程1`++x`，然后，线程2`++x`，结果是2
- 线程2`++x`，然后，线程1`++x`，结果是2
除此之外，不会出现第三种情况，线程1、2孰先孰后，取决于线程调度，但不影响最终结果。

Linux操作系统和C/C++编程语言都提供了整型原子变量，这类原子变量非常适用于计数，或者产生序列号这样的场合。

如何保证原子性是实现层面的问题，应用程序员只需要从逻辑上理解原子性就行。某操作是原子性的，那就意味着它是一个不可细分的操作整体，用户观察它，只能看到未完成和已完成2种状态，看不到半完成状态。

### 互斥锁
前面举了很多例子，阐述多线程不加同步并发访问数据会引起什么问题。

针对线程1`write_msg` + 线程2`read_msg`的问题，如果能让线程1`write_msg`的过程中，线程2不能`read_msg`，那就不会有问题。

这个要求，其实就是要让多个线程互斥访问共享数据，即如果有一个线程在访问某共享资源（数据），那么访问同一共享资源的其他线程要等待，直到那个线程访问完，其他线程才能获得访问的机会，且同一时间，只能有一个线程对那个共享资源进行访问，简而言之，就是多线程对共享资源的访问要**串行化**。

互斥锁就是能满足上述要求的同步机制，互斥锁提供**加锁**和**解锁**两个主要接口。

互斥是排他的意思，当互斥锁被某线程锁住，那么所有试图对它加锁的线程都会被阻塞，直到该互斥量被解锁。当互斥锁被解锁，等待该锁的所有线程，只有一个会获得锁，继续执行。

我们为某个共享资源配置一个互斥锁，所有对该资源的访问，都遵从“加锁、访问、解锁”的三步曲：
```C++
DataType shared_resource;
Mutex shared_resource_mutex;

void shared_resource_visitor1() {
    // step1: 加锁
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation1
    // step3: 解锁
    shared_resource_mutex.unlock();
}

void shared_resource_visitor2() {
    // step1: 加锁
    shared_resource_mutex.lock();
    // step2: operate shared_resouce
    // operation2
    // step3: 解锁
    shared_resource_mutex.unlock();
}
```
`shared_resource_visitor1`和`shared_resource_visitor2`代表对共享资源的不同操作，多个线程可能调用同一个操作函数，也可能调用不同的操作函数。

假设线程1执行`shared_resource_visitor1()`，该函数在访问数据之前，申请加锁，如果互斥锁已经被其他线程加锁，则调用该函数的线程会阻塞在加锁操作上，直到其他线程访问完数据，释放锁（解锁），阻塞在加锁操作的线程1才会被唤醒，并尝试加锁：
- 如果没有其他线程申请该锁，那么线程1抢到锁，获得了对资源的访问权，完成操作后，释放锁。
- 如果其他线程也在申请该锁，那么：
    - 如果其他线程抢到了锁，那么线程1继续阻塞。
    - 如果线程1抢到了该锁，那么线程1将访问资源，再释放锁，其他竞争该锁的线程得以有继续执行的机会。

如果不能承受加锁失败而陷入阻塞的代价，那么可以调用互斥量的`try_lock()`接口，它在加锁失败后会立即返回。

注意：在访问资源前申请锁，是一种程序契约，通过遵守契约而获得数据一致性的保障，它并非一种硬性的限制，即如果别的线程遵从三步曲，而另一个线程不遵从这种约定，代码能通过编译且程序能运行，但结果可能是错的。