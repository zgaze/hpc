# 计算机系统基础

自美国军方1946年造出世界上第一台电子计算机（ENIAC）已经过去了70多年，这一划时代的创新产品深刻而持久的影响了世界，过去的半个多世纪，计算机技术的发展日新月异，但计算机系统背后的核心思想，如冯诺依曼（存储程序）原理、局部性原理，以及操作系统、编译器、进程、虚拟地址等重要的概念，却经受住了时间的考验，像支柱一样支撑着计算机大厦屹立不倒。

计算机系统包括硬件和软件两个部分，硬件为计算机系统提供物质基础，而软件为计算机系统注入灵魂，软硬件紧密协作，共同构建一个功能强大、应用广泛的计算机系统。

计算机的硬件包括CPU、主存（内存）和外设，各部件之间通过总线相连，总线是贯穿整个计算机系统的电子管道，它携带数字信息，并让信息在各部件之间流转。

## 硬件
- 中央处理单元（CPU）：CPU是计算机的核心部件，CPU负责解析并执行存储在内存中的指令，它从内存获取指令和数据，执行算术/逻辑运算，将结果写回内存，同时更新PC寄存器，再继续执行下一条指令，被执行的连续的指令构成指令流。
    - 寄存器文件：CPU包含一组寄存器，寄存器的宽度即机器字长，寄存器为计算单元供数，缓存计算结果。程序计数器（PC）是一个特殊寄存器，它保存下一条要执行的指令在内存中的地址。
    - 算术逻辑单元（ALU）：负责算术和逻辑运算，加减乘除等是算术运算，条件与或非等是逻辑运算，ALU的源操作数取决于指令类型，既可以是寄存器，也可以是内存地址，但通常两个操作数不能同时为内存地址。
    - 指令集：指令集跟架构有关，不同CPU支持不同的指令集，比如Intel/AMD公司的X86-64指令集与ARM指令集不同，指令集是指令的集合，描述了每条指令的执行效果。
- 主存储器：也叫内存，用来存放程序和数据，逻辑上，主存是一个连续的字节数组，每个字节都有唯一的编号，这个编号即内存地址。
- 总线：总线传递信号和数据，CPU通过系统总线跟内存以及外设相连，总线就像人身上的神经，连接内存的总线是一种系统总线，PCI总线用于连接外设。
- CPU和主存是计算机不可或缺的核心部件，除此之外，包括磁盘、键盘、鼠标、显示器等在内的外设对于计算机系统而言并非必不可少，外设通过PCI总线与CPU相连，外设为计算机与人交互提供便利。

## 软件

### 操作系统
- 操作系统是覆盖在硬件上的系统软件，它直接管理和调度这些硬件资源，没有操作系统，这些硬件什么也做不了。
- 为了维护系统的安全性，不至于让失控的应用程序瘫痪整个系统，所以操作系统，会向应用程序提供某种安全机制（通过系统调用陷入内核）来访问硬件资源，并提供某种一致的编程接口（比如posix接口）。
- 操作系统要同时运行多个任务，所以，操作系统抽象出进程、虚拟内存、文件等概念，从而在进程间复用资源，并做好平衡和隔离。
- 操作系统要跟硬件直接打交道，所以，操作系统一般使用C/汇编等系统向的编程语言开发。

### 进程和进程调度
进程，是一个运行中的程序，操作系统提供一种假象，即每个进程在独占的使用CPU、内存、磁盘和I/O外设。在进程自身看来，CPU一条接着一条地执行程序代码节的指令，内存里只装载着该程序的代码和数据。实际上，计算机系统通过抽象出进程这个概念，让系统上的多个任务能并发的执行，每个任务都像在独占的使用硬件。

近十多年以来，处理器技术向多处理器（CPU）和多核（Core）方向发展，虽然在技术和工艺上，多CPU和多Core有着显著的不同，但是，从应用程序员视角看来，他们并没有什么不同，他们都是一个被称为逻辑处理器的东西，它代表一个着能独立做算术逻辑运算的器件。

虽然处理核心的数量相比之前有了显著增加，但一般而言，系统核心的数量依然少于系统上同时运行着的进程数，进程也叫任务，在同一时刻，并不是每个任务都能分配到处理器资源，处理器资源依然是稀缺资源，操作系统负责管理处理器和任务（进程），按时间分片的方式，把处理器分配给任务执行，任务在处理器上执行过一段时间后，操作系统会调度其他任务到该处理器上运行，但因为每个时间分片相对于用户而言很短，所以，虽然实际上，任务在处理器上交替执行，但用户感觉上依然是每个任务在独占的使用处理器资源。

时间片耗尽是任务被调度走的一个原因，其他的原因还包括：任务调用了一个阻塞的I/O操作、等待某个资源/条件、又或是任务主动yield让出CPU。

任务被调度到处理器上执行叫schedule-in，任务被从处理器上调度走叫schedule-out，为了能让任务恢复执行，需要保存任务的运行时状态，以便在任务再次获得处理器资源的时候能够恢复执行，这些状态信息一般保存在线程的栈里（保存寄存器的值等），任务的运行状态信息叫任务上下文（task-context），任务被再次调度执行的时候，会从栈中恢复上下文信息。

操作系统把控制权从一个任务切换到另一个任务，叫上下文切换，即保存当前任务上下文，恢复新任务上下文，将控制权转移给新任务。

如果我们把计算机系统想象成一个工厂，那么CPU/Core相当于工人，核心的个数，是工厂的最大并行度，你多招一个工人，并行度就增加一，然后工人需要完成的工作，就相当于进程，1个工人可能需要完成许多项工作，可能一个工人在做一件事情的时候，有更紧迫的事情插入进来，这时候工人需要放下当前处理的工作，转去处理更紧迫的工作。

即使在计算机只有一个处理器一个核心的早期，机器上的多个任务依然是并发的，并发跟核心的数量没有必然关心，并发是任务被交替执行的情况，多个任务的开始结束时间有交叠，那么这多个任务就是并发任务，我们可以称呼他们被并发执行，而并行，是指齐头并进，在同一时间，多个任务被同时处理，多处理器多核是并行的物质基础。

#### 上下文切换的开销
上下文切换的开销有多大呢？下面介绍一个通过block I/O的方法测试上下文开销的方法：

- 启动2个进程，进程A和进程B通过XSI消息队列进行进程间通信
- 进程A和进程B的主要逻辑都是执行一个百万次循环
- 进程A在循环内，发送一个类型为A2B的消息，然后接收一个类型为B2A的消息
- 进程B在循环内，接收一个类型为A2B的消息，然后接收一个类型为A2B的消息
- A2B和B2A是消息类型的整型枚举值，进程A发送A2B类型消息，接收B2A类型消息，进程B发送B2A消息，接收A2B类型消息
- 发送（send）和接收（recv）都不带no-wait FLAG，这样的话，如果消息队列没有对应类型消息的话，接收消息会阻塞
- 把A/B进程都绑定到core1上执行，以下面的方式启动：
    - taskset -c 1 ./a
    - taskset -c 1 ./b
- 进程A在发送消息后，接收B2A消息的时候会阻塞（因为消息队列里还没有B2A类型的消息），让出Core1，操作系统调度进程B到Core1上运行
- B收消息，正常；再发消息，也正常；B进入下一轮循环，收消息，阻塞，被调度走；换进程A执行
- 如上，就会出现A和B进程在Core1上依次交替执行的情况，频繁调度A/B进程会导致频繁的context swap
- 加上时间统计，差不多1000万次循环，需要33秒，所以，单次context swap平均耗时3.5微秒

#### 用户态、内核态
操作系统为了保护系统的安全，为应用程序提供一个统一的界面，应用程序运行在操作系统之上，并通过一个特殊的系统调用陷入内核。

一个进程在CPU上运行，那么它只会有2种可能。

- 一种是进程运行在用户态，执行普通权限指令
- 另一种是进程陷入内核，运行在内核态，执行内核代码

### 编译器
编译器负责把应用程序翻译成能在操作系统上执行的机器代码，我们通过C/C++/Java等高级语言编写的程序，经过编译器的多个步骤处理，一步步被转换为能贴近机器运行的低级机器代码，编译器既需要处理高级语言语法的细节，又需要处理跟操作系统的交互细节，编译器是一整套工具链的集合，比如GCC是用于处理C语言的编译器，它包含预处理器CPP、编译器GCC、链接器LD等，从机器码到编程语言的转换过程叫逆向工程，机器码与汇编语言是一一对应的，但机器码到高级语言并非一一对应。

### 信息的表示