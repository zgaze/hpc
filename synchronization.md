
# 线程同步

进程内的多个线程共享同一虚拟地址空间，每个线程都是一个独立的执行流，所以多个线程对应多个执行流，多个执行流会出现竞争同一资源的情况，这些资源包括程序变量、打开的文件句柄、套接字等，如果不加以控制和协调，则有可能出现数据不一致，从而导致错误的运行结果。

并发编程的错误非常诡谲且难以定位，它总是隐藏在某个的角落，大多数时候，程序运转良好，然而根据墨菲定律，凡是可能出错，就一定会出错。

## 为什么需要多线程同步？

### 例子1
举一个例子：有一个货物售卖程序，全局变量int item_num记录某商品的数量，它被初始值为100，代表该商品可售卖数量为100件；售卖函数检查剩余商品数，如果剩余商品数大于等于售卖数量，则扣除商品件数，并返回成功，否则返回失败，代码如下：

```
bool sell(int num) {
    if (item_num >= num) {
        item_num -= num;
        return true;
    }
    return false;
}
```

单线程下，程序运转良好，但在多线程环境下，会出错。

假设线程t1和t2，分别在core1和core2同时执行，t1执行sell(50), t2执行sell(100)，如果2个执行流同时执行到if (item_num >= num)这一行判断语句，因为item_num的值为100，所以2个线程的条件检查都通过，然后线程t1从内存中加载item_num(100)到寄存器，执行减法运算（100-50 => 50）更新寄存器，这时候，线程t2也从内存加载item_num(100)到另一个核心的寄存器，执行减法运算（100-100 => 0）更新寄存器，然后t1和t2线程先后把各自寄存器里的新值store到内存。

假设t1线程先store，这时候item_num变成50，t2线程再执行store，内存中的item_num的值被覆盖，被替换为0；如果t2先于t1完成store，则item_num的最终值为50。无论哪种情况，结果都是错误的，我们只有100件商品，却超卖出150件。

如果程序在单CPU的机器上运行，t1线程和t2线程并发（非并行）交错执行，因为只有一个CPU，所以同一时刻，只有一个线程在执行，假设t1在CPU上执行，它把item_num load到寄存器，完成判断，这时候，发生线程调度（比如t1的时间配额耗尽），t2被调度到CPU上执行，然后t2依次完成load、check、compute和store操作，然后t1又被调度到CPU上恢复执行，item -= 50的结果为50，因为t1会直接用寄存器中的item_num拷贝（100），所以t1线程执行后，新值50被store入item_num所在内存，我们期望t1或者t2的sell只有一个操作成功，但结果并非如此。

让我们再看一个例子：

### 例子2
全局变量int count用来计数，我们启动100个线程，每个线程的处理逻辑：在1000次循环里累加count；主函数启动线程并等待所有线程执行完成，程序退出前打印count数值，代码如下:

```
#include <thread>
#include <iostream>

int count = 0;

void thread_proc() {
    for (int i = 0; i < 1000; ++i) {
        ++count;
    }
}

int main() {
    std::thread threads[100];
    for (auto &x : threads) {
        x = std::move(std::thread(thread_proc));
    }
    for (auto &x : threads) {
        x.join();
    }
    std::cout << "count:" << count << std::endl;
    return 0;
}
```
我的机器上打印count:97424，而我们期望的结果是100*1000=100000，为什么会这样？

简单的一行++count，实际上包括：从内存加载全局变量的值到寄存器（load），寄存器中更新值（increament），将寄存器中的新值存入内存（store），因为多个线程并发/并行执行，而load/increament/store的三步不是原子的，所以多个线程可能加载了相同的旧值，再寄存器各自更新，再写入count的变量位置，所以导致最终值比期望的10000小，而且运行多次，会出现不同的结果。

## 问题出在哪里？
上述2个例子，都证明：不加控制的多线程并发/并行执行，会导致数据不一致，从而产生错误的结果，所以，需要有某种同步机制，协调多线程的运行，确保结果的正确性。

上述程序的问题都出在多个执行流对相同数据的竞争访问，连续的多个操作并非原子的，且多个执行流对数据都不只是简单的读，而是包含了写操作。

总结一下，只有同时满足下面情况，才需要做多线程同步：
- 数据竞争是前提条件，多线程对同一数据的并发访问
- 多线程读写，所有线程对数据只是读的话，没有问题；必须有线程对数据进行写（修改）
- 时间上，同时或者交错，如果时间上能错开，则也没有问题
- 出现的不一致数据结果，是不能忍受的错误，否则，也不必同步

## 我们保护的到底是什么？
我们保护的是数据，而非代码

## 多线程同步机制有哪些？

### 互斥锁和RAII
互斥锁，本质上是做串行化，即在同一时间点，被保护的数据的临界代码，只会有一个执行流正在运行，直到这段临界代码执行完，其他执行流才有机会进入这段临界代码，这就从根本上杜绝了某个数据被多个执行流交错访问。

通过互斥锁对数据进行保护，需要开发者遵从约束，按某种规定的方式编写数据访问代码，这种约束是对程序员的，它并非某种强制的限制。

比如使用互斥量对数据x进行并发访问控制，假设有2处代码对该数据竞争访问，其中一处用互斥量做了保护，而另外一处，没有使用互斥锁加以保护，则代码能依然通过编译，程序依然能运行，只是结果上可能是错误，这个跟现实中没有钥匙开锁就不能拿到（访问）数据是不一样的。

### 自旋锁
在cpu核上自旋，粘着cpu不停的测试，直到其他cpu解锁，这是一种消耗cpu的加锁方式，适合持有锁的时间非常短的情况，它基于一种假设，睡眠导致的调度开销大于在cpu上自旋测试的开销。

### 读写锁
写排他，读并行，适合多读少写的场景，可以提升吞吐。

### 条件变量（生产者-消费者模式）
需要配合互斥量使用，常用于生产者消费者模式

### 原子操作
CAS

### 内存屏障

### lock-free

## 相关概念
### 线程安全
不访问全局变量，没有static local变量，只影响参数，无副作用

### 线程可重入

### 锁的粒度
锁的粒度太大，会影响并发，导致性能下降，但锁的粒度太大，会增加代码复杂度，需要平衡。

### 锁的范围
尽量减少锁的范围，不必锁覆盖的代码范围越小越好。

### 死锁
死锁常见于两种情况。

#### ABBA锁
假设程序中有2个资源X和Y，分别被锁A和B保护，线程1持有锁A后，想要访问资源Y，而访问资源Y之前需要申请锁B，而如果线程2正持有锁B，并想要访问资源X，为了访问资源X，所以线程2需要申请锁A。

线程1和线程2分别持有锁A和B，并都希望申请对方持有的锁，因为线程申请对方持有的锁，得不到满足，所以便会陷入等待，也就没有机会释放自己持有的锁，对方执行流也就没有办法继续前进，导致相持不下，无限互等，导致死锁。

上述的情况似乎很明显，但如果代码量很大，有时候，这种死锁的逻辑不会这么浅显，它被复杂的调用逻辑所掩盖，但抽茧剥丝，最根本的原因就是上面描述的那样。

我们描述了死锁发生的典型场景，这种情况叫ABBA锁，既某个线程持有A锁申请B锁，而另一个线程持有B锁申请A锁。这种情况可以通过try lock实现，尝试获取锁，如果不成功，则释放自己持有的锁，而不一根筋下去。

#### 自死锁
对于不自持重复加锁的锁，如果线程持有某个锁，而后又再次申请锁，因为该锁已经被自己持有，再次申请锁必然得不到满足，从而导致死锁。

## 这种情况需要加锁吗？

## 扩展知识
### 分布式锁
